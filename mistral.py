from huggingface_hub import InferenceClient

# Substitueix per la teva clau d'API
client = InferenceClient(
    provider="hf-inference",
    api_key="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",
)

#  Sol路licitem l'input del log a l'usuari
log = input("Introdueix el log d'Apache que vols analitzar: ")

#  Optimitzaci贸 del prompt per reduir l'煤s de tokens
prompt = f"Explica detalladament el seg眉ent log d'Apache i detecta possibles problemes:\n\n{log}\n"

#  Enviem la petici贸 al model
completion = client.chat.completions.create(
    model="mistralai/Mistral-7B-Instruct-v0.3",
    messages=[{"role": "user", "content": prompt}],
)

#  Imprimim la resposta
print("\n Explicaci贸 del log:\n")
print(completion.choices[0].message.content)
